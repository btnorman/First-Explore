{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annual-glenn",
   "metadata": {},
   "source": [
    "# Example of loading, and running the Ray Maze models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparative-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:41:38.246550: I external/org_tensorflow/tensorflow/compiler/xla/service/service.cc:169] XLA service 0x563554f9da00 initialized for platform Interpreter (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-08 18:41:38.246582: I external/org_tensorflow/tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Interpreter, <undefined>\n",
      "2024-12-08 18:41:38.249025: I external/org_tensorflow/tensorflow/compiler/xla/pjrt/tfrt_cpu_pjrt_client.cc:215] TfrtCpuClient created.\n",
      "2024-12-08 18:41:38.438782: I external/org_tensorflow/tensorflow/compiler/xla/service/service.cc:169] XLA service 0x563554f9cab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-08 18:41:38.438810: I external/org_tensorflow/tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-08 18:41:38.439265: I external/org_tensorflow/tensorflow/compiler/xla/pjrt/gpu/se_gpu_pjrt_client.cc:198] Using BFC allocator.\n",
      "2024-12-08 18:41:38.439329: I external/org_tensorflow/tensorflow/compiler/xla/pjrt/gpu/gpu_helpers.cc:105] XLA backend allocating 14152767897 bytes on device 0 for BFCAllocator.\n"
     ]
    }
   ],
   "source": [
    "### script set up\n",
    "\n",
    "import os  # ensure we can import the lte_code\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "sys.path\n",
    "\n",
    "from prep_args import C\n",
    "import prep_args\n",
    "\n",
    "script_setting = {'batchsize' : C((128,)),\n",
    "                  'ep_len' : C((20,)),\n",
    "                  'weighting' : C((True,)),\n",
    "                  'seed' : C((42,)),\n",
    "                  't' : C((1,)),\n",
    "                  'minval' : C((-1,)),\n",
    "                  'num_eps' : C((3,)),\n",
    "                  'side_rays' : C((7,))}\n",
    "\n",
    "# n = prep_args.count(script_setting)\n",
    "# args = prep_args.get_args(0)\n",
    "# k = args.SBATCHID\n",
    "k = 0\n",
    "prep_args.set_run_parameters(script_setting, k)\n",
    "\n",
    "run_name = ''.join((f\"{key}_{script_setting[key]}\" for key in script_setting.keys()))\n",
    "checkpoint_dir = run_name\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "ACT_DIM = 3\n",
    "STATE_DIM = 2*(2*script_setting['side_rays']+1)\n",
    "\n",
    "### From Notebook:\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "from lte_code.lte_model5 import LTE\n",
    "from transformers import DecisionTransformerConfig\n",
    "\n",
    "config = DecisionTransformerConfig(act_dim=ACT_DIM, state_dim=STATE_DIM,\n",
    "                                   n_head=4, n_layer=4, hidden_size=128)\n",
    "num_training_steps = num_epochs*1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import optax\n",
    "def warmup_linear_schedule(\n",
    "    learning_rate: float,\n",
    "    total_steps: int,\n",
    "    warmup_ratio: int):\n",
    "    warmup_steps = int(total_steps*warmup_ratio)\n",
    "    schedules = [\n",
    "      optax.linear_schedule(\n",
    "          init_value=0,\n",
    "          end_value=learning_rate,\n",
    "          transition_steps=warmup_steps),\n",
    "      optax.linear_schedule(\n",
    "          init_value=learning_rate,\n",
    "          end_value=0,\n",
    "          transition_steps= total_steps - warmup_steps),]\n",
    "    return optax.join_schedules(schedules, [warmup_steps])\n",
    "\n",
    "\n",
    "schedule = warmup_linear_schedule(learning_rate=1e-4,\n",
    "                                  total_steps=num_training_steps,\n",
    "                                  warmup_ratio=0.1)\n",
    "optimizer = optax.chain(\n",
    "  optax.clip(0.25),\n",
    "  optax.adamw(learning_rate=schedule, weight_decay=1e-4),\n",
    ")\n",
    "\n",
    "model = LTE(config)\n",
    "key = jax.random.PRNGKey(script_setting['seed'])\n",
    "pkey, key = jax.random.split(key)\n",
    "batch_size=script_setting['batchsize']\n",
    "\n",
    "from maze3 import TinyWorld\n",
    "\n",
    "\n",
    "env = TinyWorld(w=3, h=3, side_rays=script_setting['side_rays'],\n",
    "                ep_len=20, batch_size=128, concat_obs=True)\n",
    "batch_step = env.step\n",
    "batch_mset = env.meta_reset\n",
    "\n",
    "\n",
    "def rollout_sequence(states, actions):\n",
    "    \"\"\"takes a batch of states\n",
    "    and a batch of actions [batch_dim, seq_len, act_dim]\n",
    "    and calculates the rewards, [batch_dim, seq_len, rewards]\"\"\"\n",
    "    def step_state_reward(state, action):\n",
    "        state = batch_step(state, action)\n",
    "        return state, (state.obs, state.reward)\n",
    "    states, x = jax.lax.scan(step_state_reward,\n",
    "                                   states,\n",
    "                                   jnp.swapaxes(actions, 0, 1))\n",
    "    obs, rewards = jax.tree_map(lambda a: jnp.swapaxes(a, 0, 1), x)\n",
    "    return obs, rewards\n",
    "\n",
    "def tokenize(actions_batch, rewards_batch):\n",
    "    @jax.vmap\n",
    "    @jax.vmap\n",
    "    def one_hot(act):\n",
    "        return jnp.zeros(shape=ACT_DIM).at[act].set(1)\n",
    "    action_tokens = one_hot(actions_batch)\n",
    "    return action_tokens, jnp.expand_dims(rewards_batch, 2)\n",
    "\n",
    "### Functions for autoregressive sampling\n",
    "\n",
    "from flax.core.frozen_dict import unfreeze, freeze\n",
    "def feed_token(model_params, cache,\n",
    "               obs, rewards, actions,\n",
    "               timesteps, ep_nums):\n",
    "    \"\"\"takes the parameters, the current model cache,\n",
    "    the token, token_type, and time_step\n",
    "    and feeds them to the model updating the cache\n",
    "    \n",
    "    Note, can process multiple tokens at once\n",
    "    token should be [batch_size, seq_len, token_dim]\n",
    "    and token_type [batch_size, seq_len]\n",
    "    time_step [batch_size, seq_len]\"\"\"\n",
    "    ra = unfreeze(model_params)\n",
    "    ra['seq']['cache'] = cache['cache']\n",
    "    return model.apply(params=ra, mutable=['cache'],\n",
    "                       states=obs,\n",
    "                       rewards=rewards,\n",
    "                       actions=actions,\n",
    "                       timesteps=timesteps,\n",
    "                       ep_nums=ep_nums)\n",
    "\n",
    "num_eps = script_setting['num_eps']\n",
    "ep_len = script_setting['ep_len']\n",
    "\n",
    "cache_len = (num_eps+1)*(ep_len+1)\n",
    "\n",
    "from functools import partial\n",
    "@partial(jax.jit, static_argnames=\"batch_size\")\n",
    "def init_cache(model_params, batch_size):\n",
    "    return model.apply(\n",
    "        params=model_params,\n",
    "        init_cache=True,\n",
    "        mutable=['cache'],\n",
    "        states=jnp.zeros((batch_size, cache_len, STATE_DIM)),\n",
    "        rewards=jnp.zeros((batch_size, cache_len, 1)),\n",
    "        actions=jnp.zeros((batch_size, cache_len, ACT_DIM)),\n",
    "        timesteps=jnp.zeros((batch_size, cache_len), dtype=int),\n",
    "        ep_nums=jnp.zeros((batch_size, cache_len), dtype=int))[1]\n",
    "\n",
    "def episode_roll_out(state, ep_no,\n",
    "                     cache_roll, cache_pred,\n",
    "                     params_roll, params_pred,\n",
    "                     key, sample_f, pred_f, step_num=ep_len,\n",
    "                     return_data=False):\n",
    "    init_ob, init_r = state.obs, state.reward\n",
    "    action_token = jnp.zeros((batch_size, 1, ACT_DIM))\n",
    "    obs_token = jnp.expand_dims(init_ob, axis=1)\n",
    "    reward_token = init_r[..., None, None]\n",
    "    \n",
    "    @jax.vmap\n",
    "    def one_hot(act):\n",
    "        return jnp.zeros(shape=ACT_DIM).at[act].set(1)\n",
    "    @jax.vmap\n",
    "    def ind(a, i):\n",
    "        return a[i]\n",
    "    \n",
    "    def auto_step(carry, a_key):\n",
    "        (state, timestep, ep_no,\n",
    "         cache_roll, cache_pred,\n",
    "         action_token, obs_token, reward_token,\n",
    "         entropies) = carry\n",
    "        roll_ans, cache_roll = feed_token(params_roll, cache_roll,\n",
    "                                          actions=action_token,\n",
    "                                          obs=obs_token,\n",
    "                                          rewards=reward_token,\n",
    "                                          timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                              dtype=int)+timestep,\n",
    "                                          ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                            dtype=int)+ep_no)\n",
    "        pred_ans, cache_pred = feed_token(params_pred, cache_pred,\n",
    "                                          actions=action_token,\n",
    "                                          obs=obs_token,\n",
    "                                          rewards=reward_token,\n",
    "                                          timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                              dtype=int)+timestep,\n",
    "                                          ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                            dtype=int)+ep_no)\n",
    "        samp_logits = sample_f(roll_ans.last_hidden_state[:, -1, :])\n",
    "        samp_logits = jax.lax.stop_gradient(samp_logits)\n",
    "        action = jax.random.categorical(a_key, samp_logits)\n",
    "        state = env.step(state, action)\n",
    "        \n",
    "        action_token = jnp.expand_dims(one_hot(action), axis=1)\n",
    "        obs_token = jnp.expand_dims(state.obs, axis=1)\n",
    "        reward_token = state.reward[..., None, None]\n",
    "\n",
    "        pred_logits = pred_f(pred_ans.last_hidden_state[:, -1, :])\n",
    "        pred_ent = optax.softmax_cross_entropy_with_integer_labels(samp_logits\n",
    "                                                                   + pred_logits,\n",
    "                                                                   action)\n",
    "        carry = (state, timestep+1, ep_no,\n",
    "                 cache_roll, cache_pred,\n",
    "                 action_token, obs_token, reward_token,\n",
    "                 entropies + pred_ent)\n",
    "        if not return_data:\n",
    "            return carry, None\n",
    "        else:\n",
    "            return carry, (samp_logits, pred_logits, action, state)\n",
    "    \n",
    "    carry = (state, 0, ep_no,\n",
    "             cache_roll, cache_pred,\n",
    "             action_token, obs_token, reward_token,\n",
    "             jnp.zeros(batch_size))\n",
    "    carry, xs = jax.lax.scan(auto_step, carry, jax.random.split(key, step_num))\n",
    "    (state, timestep, ep_no, cache_roll, cache_pred,\n",
    "     action_token, obs_token, reward_token, entropies) = carry\n",
    "    \n",
    "    roll_ans, cache_roll = feed_token(params_roll, cache_roll,\n",
    "                                      actions=action_token,\n",
    "                                      obs=obs_token,\n",
    "                                      rewards=reward_token,\n",
    "                                      timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                          dtype=int)+timestep,\n",
    "                                      ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                        dtype=int)+ep_no)\n",
    "    pred_ans, cache_pred = feed_token(params_pred, cache_pred,\n",
    "                                      actions=action_token,\n",
    "                                      obs=obs_token,\n",
    "                                      rewards=reward_token,\n",
    "                                      timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                          dtype=int)+timestep,\n",
    "                                      ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                        dtype=int)+ep_no)\n",
    "    if not return_data:\n",
    "        return state, ep_no+1, cache_roll, cache_pred, entropies\n",
    "    else:\n",
    "        return state, ep_no+1, cache_roll, cache_pred, entropies, xs\n",
    "\n",
    "\n",
    "def exploit(state, ep_no,\n",
    "            cache_roll, cache_pred,\n",
    "            params_roll, params_pred, \n",
    "            key, samp_t = 1, step_num=ep_len,\n",
    "            return_data=False, rand_roll=False):\n",
    "    \"\"\"autoregressively exploits\n",
    "    \n",
    "    sample_f = exploit with epsilon and temperature\n",
    "    pred_fs = (exploit (no epsilon, no temperature), non-exploit)\n",
    "    \n",
    "    return updated state, cache, episode return, accumulated cross entropy sums\n",
    "    \"\"\"\n",
    "    ## sample_f updated based on epsilon and t, as done before\n",
    "    ## pred_fs as before, then the following\n",
    "    def sample_exploit(hidden_state):\n",
    "        return jax.lax.stop_gradient(model.pred_exp.apply(params_roll['pred_max'],\n",
    "                                                          hidden_state) * samp_t)\n",
    "    def pred_max(hidden_state):\n",
    "        return model.pred_exp.apply(params_pred['pred_max'],\n",
    "                                      hidden_state)\n",
    "    return episode_roll_out(state=state, ep_no=ep_no,\n",
    "                            params_roll=params_roll,\n",
    "                            params_pred=params_pred,\n",
    "                            cache_roll=cache_roll,\n",
    "                            cache_pred=cache_pred,\n",
    "                            key=key,\n",
    "                            sample_f=sample_exploit,\n",
    "                            pred_f=pred_max,\n",
    "                            return_data=return_data,\n",
    "                            step_num=step_num)\n",
    "\n",
    "\n",
    "def explore(state, ep_no,\n",
    "            cache_roll, cache_pred,\n",
    "            params_roll, params_pred, \n",
    "            key, samp_t = 1, step_num=ep_len,\n",
    "            return_data=False, rand_roll=False):\n",
    "    \"\"\"autoregressively exploits\n",
    "    \n",
    "    sample_f = exploit with epsilon and temperature\n",
    "    pred_fs = (exploit (no epsilon, no temperature), non-exploit)\n",
    "    \n",
    "    return updated state, cache, episode return, accumulated cross entropy sums\n",
    "    \"\"\"\n",
    "    def sample_exploit(hidden_state):\n",
    "        return jax.lax.stop_gradient(model.pred_exp.apply(params_roll['pred_exp'],\n",
    "                                                          hidden_state) * samp_t)\n",
    "    def pred_max(hidden_state):\n",
    "        return model.pred_exp.apply(params_pred['pred_exp'],\n",
    "                                      hidden_state)\n",
    "    return episode_roll_out(state=state, ep_no=ep_no,\n",
    "                            cache_roll=cache_roll,\n",
    "                            cache_pred=cache_pred,\n",
    "                            params_roll=params_roll,\n",
    "                            params_pred=params_pred,\n",
    "                            key=key,\n",
    "                            sample_f=sample_exploit,\n",
    "                            pred_f=pred_max,\n",
    "                            return_data=return_data,\n",
    "                            step_num=step_num)\n",
    "\n",
    "\n",
    "def train_exploit_explore(params_pred, params_roll,\n",
    "                          key, step_num=ep_len, ep_num=num_eps,\n",
    "                          samp_t=1, return_data=False,\n",
    "                          weighted=False):\n",
    "    \"\"\"does iterated rollouts\"\"\"\n",
    "    skey, rkey = jax.random.split(key, 2)\n",
    "    state = env.meta_reset(skey)\n",
    "    cache_roll = init_cache(params_roll, batch_size)\n",
    "    cache_pred = init_cache(params_pred, batch_size)\n",
    "\n",
    "    def epstep(carry, key):\n",
    "        (cache_roll, cache_pred, n, max_in_context,\n",
    "         max_ent, exp_ent) = carry \n",
    "\n",
    "        e_key, m_key = jax.random.split(key, 2)\n",
    "        \n",
    "        exp_ans = explore(state, n,\n",
    "                          cache_roll=cache_roll,\n",
    "                          cache_pred=cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=e_key,\n",
    "                          samp_t=samp_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies, exp_xs) = exp_ans\n",
    "        else:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies) = exp_ans\n",
    "        \n",
    "        max_ans = exploit(state, e_n,\n",
    "                          cache_roll=exp_cache_roll,\n",
    "                          cache_pred=exp_cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=m_key,\n",
    "                          samp_t=samp_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (max_state, m_n, max_cache_roll, max_cache_pred, \n",
    "             m_entropies, max_xs) = max_ans\n",
    "        else:\n",
    "            (max_state, m_n, max_cache_roll, max_cache_pred, \n",
    "             m_entropies) = max_ans\n",
    "            \n",
    "\n",
    "        mul_max = max_state.cr >= max_in_context\n",
    "        mul_exp = max_state.cr > max_in_context\n",
    "        if weighted:\n",
    "            mul_max = mul_max*(1+max_state.cr-max_in_context)\n",
    "            mul_exp = mul_exp*(1+max_state.cr-max_in_context)\n",
    "        max_in_context = jnp.maximum(jnp.maximum(exp_state.cr, max_state.cr), max_in_context)\n",
    "        \n",
    "        max_ent = (m_entropies*mul_max).mean() + max_ent\n",
    "        exp_ent = (e_entropies*mul_exp).mean() + exp_ent\n",
    "        \n",
    "        carry = (exp_cache_roll, exp_cache_pred, e_n, max_in_context,\n",
    "                 max_ent, exp_ent)\n",
    "        \n",
    "        if return_data:\n",
    "            return carry, (exp_xs, max_xs, max_state.cr)\n",
    "        return carry, (max_state.cr, exp_state.cr)\n",
    "    \n",
    "    carry = (cache_roll, cache_pred, 0,\n",
    "             jnp.zeros(shape=(batch_size,)),\n",
    "             jnp.zeros(()), jnp.zeros(()))\n",
    "    carry, max_vals = jax.lax.scan(epstep, carry, jax.random.split(rkey, ep_num))\n",
    "    \n",
    "    if return_data:\n",
    "        return carry, max_vals\n",
    "    else:\n",
    "        max_ent, exp_ent = carry[-2:]\n",
    "        max_reward, exp_reward = max_vals\n",
    "        return ((max_ent+exp_ent)/ep_num,\n",
    "                (max_ent, exp_ent,\n",
    "                 max_reward.mean(axis=1), exp_reward.mean(axis=1)))\n",
    "\n",
    "    \n",
    "@jax.jit\n",
    "def train_step(carry, _):\n",
    "    params_roll, params_pred, opt_state, key, samp_t = carry\n",
    "    next_key, data_key, drop_key = jax.random.split(key, 3)\n",
    "    loss, grad = jax.value_and_grad(train_exploit_explore,\n",
    "                                    has_aux=True)(params_pred, params_roll=params_roll, key=data_key, samp_t=samp_t,\n",
    "                                                  weighted=script_setting['weighting'])\n",
    "    updates, opt_state = optimizer.update(grad, opt_state, params_pred)\n",
    "    params_pred = optax.apply_updates(params_pred, updates)\n",
    "    return (params_roll, params_pred, opt_state, next_key, samp_t), loss\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(carry, _):\n",
    "    params_roll, params_pred, opt_state, key, samp_t = carry\n",
    "    next_key, data_key, drop_key = jax.random.split(key, 3)\n",
    "    loss, grad = jax.value_and_grad(train_exploit_explore,\n",
    "                                    has_aux=True)(params_pred, params_roll=params_pred, key=data_key, samp_t=10)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state, params_pred)\n",
    "    params_pred = optax.apply_updates(params_pred, updates)\n",
    "    return (params_roll, params_pred, opt_state, next_key, samp_t), loss  \n",
    "\n",
    "\n",
    "### Checkpointing Logic:\n",
    "\n",
    "\n",
    "# import wandb\n",
    "# wandb.init(project=\"LTE_doom\", resume=\"allow\")\n",
    "# wandb.config.update({'script_setting' : script_setting} | {'new_explore_cond' : True})\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "key1, key2 = jax.random.split(key, 2)\n",
    "# to train first model\n",
    "init_params = model.init(key1)\n",
    "opt_state = optimizer.init(init_params)\n",
    "carry = (init_params, init_params, opt_state, key2, 0)\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "\n",
    "# if not os.path.isdir(checkpoint_dir):\n",
    "#     if os.path.exists(checkpoint_dir):\n",
    "#         raise Exception(\"the checkpoint directory is not a directory!\")\n",
    "#     else:\n",
    "#         os.makedirs(checkpoint_dir)\n",
    "# path = os.path.join(checkpoint_dir, 'run_data.pkl')\n",
    "# if os.path.exists(path):\n",
    "#     with open(path, 'rb') as file:\n",
    "#         carry, epoch = pickle.load(file)\n",
    "#         print(\"loaded checkpoint\")\n",
    "# else:\n",
    "#     print(\"no checkpoint found, initializing instead\")  \n",
    "\n",
    "\n",
    "# def save(name, carry, epoch):\n",
    "#     None\n",
    "#     if not os.path.isdir(checkpoint_dir):\n",
    "#         if os.path.exists(checkpoint_dir):\n",
    "#             raise Exception(\"the checkpoint directory is not a directory!\")\n",
    "#         else:\n",
    "#             os.makedirs(checkpoint_dir)\n",
    "#     with open(os.path.join(checkpoint_dir, f'tmp_{name}.pkl'), 'wb') as file:\n",
    "#         pickle.dump((carry, epoch), file=file)\n",
    "#     os.replace(os.path.join(checkpoint_dir, f'tmp_{name}.pkl'),\n",
    "#                os.path.join(checkpoint_dir, f'{name}.pkl'))\n",
    "\n",
    "\n",
    "# while epoch < num_epochs:\n",
    "#     carry, losses = jax.lax.scan(train_step,\n",
    "#                                  carry, None, length=1000)\n",
    "#     (loss, (max_ent, exp_ent, max_reward, exp_reward)) = losses\n",
    "#     _, (_, (_, _, eval_mr, eval_er)) = eval_step(carry, None)\n",
    "#     break\n",
    "#     wandb.log({\"loss\" : loss.mean(),\n",
    "#                \"max_ent\" : max_ent.mean(),\n",
    "#                \"exp_ent\" : exp_ent.mean()} |\n",
    "#               {f\"max_r_{i}\" : max_reward[:, i].mean() for i in range(max_reward.shape[-1])} |\n",
    "#               {f\"exp_r_{i}\" : exp_reward[:, i].mean() for i in range(max_reward.shape[-1])} |\n",
    "#               {f\"eval_max_r_{i}\" : eval_mr[i] for i in range(max_reward.shape[-1])} |\n",
    "#               {f\"eval_exp_r_{i}\" : eval_er[i] for i in range(max_reward.shape[-1])} |\n",
    "#               {\"epoch\" : epoch})\n",
    "\n",
    "#     if (epoch+1) % 5 == 0:\n",
    "#         (roll_params, pred_params, opt_state, key, _) = carry\n",
    "#         carry = (pred_params, pred_params, opt_state, key, script_setting['t'])\n",
    "#         save(\"run_data\", carry, epoch)\n",
    "#     epoch += 1\n",
    "\n",
    "# save(\"run_data\", carry, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "functioning-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_then_exploit(params_pred, params_roll,\n",
    "                         key, step_num=ep_len, ep_num=num_eps, k=1,\n",
    "                         samp_t=1000000, return_data=False):\n",
    "    \"\"\"does iterated rollouts\"\"\"\n",
    "    skey, rkey = jax.random.split(key, 2)\n",
    "    state = env.meta_reset(skey)\n",
    "    cache_roll = init_cache(params_roll, batch_size)\n",
    "    cache_pred = init_cache(params_pred, batch_size)\n",
    "    \n",
    "    def explore_ep(carry, key):\n",
    "        (cache_roll, cache_pred, n) = carry \n",
    "        \n",
    "        e_key, m_key = jax.random.split(key, 2)\n",
    "        exp_ans = explore(state, n,\n",
    "                          cache_roll=cache_roll,\n",
    "                          cache_pred=cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=e_key,\n",
    "                          samp_t=samp_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies, exp_xs) = exp_ans\n",
    "        else:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies) = exp_ans\n",
    "        \n",
    "        carry = (exp_cache_roll, exp_cache_pred, e_n)\n",
    "        if return_data:\n",
    "            return carry, (exp_xs, exp_state.cr)\n",
    "        return carry, (exp_state.cr)\n",
    "    \n",
    "    def exploit_ep(carry, key):\n",
    "        (cache_roll, cache_pred, n) = carry \n",
    "        \n",
    "        e_key, m_key = jax.random.split(key, 2)\n",
    "        exp_ans = exploit(state, n,\n",
    "                          cache_roll=cache_roll,\n",
    "                          cache_pred=cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=e_key,\n",
    "                          samp_t=samp_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies, exp_xs) = exp_ans\n",
    "        else:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies) = exp_ans\n",
    "        \n",
    "        carry = (exp_cache_roll, exp_cache_pred, e_n)\n",
    "        if return_data:\n",
    "            return carry, (exp_xs, exp_state.cr)\n",
    "        return carry, (exp_state.cr)\n",
    "    \n",
    "    carry = (cache_roll, cache_pred, 0)\n",
    "    \n",
    "    carry, exp_vals = jax.lax.scan(explore_ep, carry, jax.random.split(rkey, k))\n",
    "    carry, max_vals = jax.lax.scan(exploit_ep, carry, jax.random.split(rkey, ep_num-k))\n",
    "    \n",
    "    return carry, (exp_vals, max_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extraordinary-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint 42\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "file = f\"batchsize_128ep_len_20weighting_Trueseed_{seed}t_1minval_0num_eps_3p_reward_0.3side_rays_7\"\n",
    "with open(file+\"/run_data.pkl\", 'rb') as file:\n",
    "    carry, epoch = pickle.load(file)\n",
    "print(\"loaded checkpoint\", seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agreed-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "key = jax.random.PRNGKey(0)\n",
    "data = []\n",
    "params_roll, params_pred, opt_state, key, samp_t = carry\n",
    "for key_seed in range(10):\n",
    "    key = jax.random.PRNGKey(key_seed)\n",
    "    ans = explore_then_exploit(params_pred, params_roll,\n",
    "                               key, step_num=ep_len, ep_num=4, k=1,\n",
    "                               samp_t=1000000, return_data=True)\n",
    "    _, (exp_vals, max_vals) = ans\n",
    "    r1 = exp_vals[0][-1].reward.mean(axis=-1) # average over batch\n",
    "    r2 = max_vals[0][-1].reward.mean(axis=-1) # average over batch\n",
    "    data.append(np.cumsum(np.concatenate((r1.reshape(-1), r2.reshape(-1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "toxic-resident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f09e6871ac0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(data).mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
