{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distant-voltage",
   "metadata": {},
   "source": [
    "# Example of loading, and running the Dark Treasure Room Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wanted-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treasure Room ATM\n"
     ]
    }
   ],
   "source": [
    "import os  # ensure we can import the lte_code\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "sys.path\n",
    "\n",
    "\n",
    "script_setting = {'roomsize' : 9,\n",
    "                  'batchsize' : 128,\n",
    "                  'weighting' : True,\n",
    "                  'seed' : 1,\n",
    "                  'k' : 8,\n",
    "                  't' : 1}\n",
    "\n",
    "\n",
    "run_name = ''.join((f\"{key}_{script_setting[key]}\" for key in script_setting.keys()))\n",
    "checkpoint_dir = run_name\n",
    "\n",
    "### From Notebook:\n",
    "\n",
    "from lte_code.bandit import Bandit\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "ACT_DIM = 5\n",
    "from lte_code.lte_model5 import LTE\n",
    "from transformers import DecisionTransformerConfig\n",
    "\n",
    "config = DecisionTransformerConfig(act_dim=ACT_DIM, state_dim=2,\n",
    "                                   n_head=4, n_layer=4, hidden_size=128)\n",
    "num_training_steps = 1000*500\n",
    "\n",
    "\n",
    "import optax\n",
    "def warmup_linear_schedule(\n",
    "    learning_rate: float,\n",
    "    total_steps: int,\n",
    "    warmup_ratio: int):\n",
    "    warmup_steps = int(total_steps*warmup_ratio)\n",
    "    schedules = [\n",
    "      optax.linear_schedule(\n",
    "          init_value=0,\n",
    "          end_value=learning_rate,\n",
    "          transition_steps=warmup_steps),\n",
    "      optax.linear_schedule(\n",
    "          init_value=learning_rate,\n",
    "          end_value=0,\n",
    "          transition_steps= total_steps - warmup_steps),]\n",
    "    return optax.join_schedules(schedules, [warmup_steps])\n",
    "\n",
    "\n",
    "schedule = warmup_linear_schedule(learning_rate=1e-4,\n",
    "                                  total_steps=num_training_steps,\n",
    "                                  warmup_ratio=0)\n",
    "optimizer = optax.chain(\n",
    "  optax.clip(0.25),\n",
    "  optax.adamw(learning_rate=schedule, weight_decay=1e-4),\n",
    ")\n",
    "\n",
    "model = LTE(config)\n",
    "key = jax.random.PRNGKey(0)\n",
    "pkey, key = jax.random.split(key)\n",
    "batch_size=1000\n",
    "\n",
    "from darkroom.darkroomofbandits import BatchedDarkRoom, save_rollout_multi_gif\n",
    "\n",
    "# print(\"Kind Room ATM\")\n",
    "print(\"Treasure Room ATM\")\n",
    "env = BatchedDarkRoom(w=script_setting['roomsize'],\n",
    "                      h=script_setting['roomsize'],\n",
    "                      batch_size=batch_size, k=script_setting['k'],\n",
    "                      rand_start=False,\n",
    "                      minval=-4)\n",
    "batch_step = env.step\n",
    "batch_mset = env.meta_reset\n",
    "\n",
    "STATE_DIM = 2\n",
    "ACT_DIM = 5\n",
    "\n",
    "def rollout_sequence(states, actions):\n",
    "    \"\"\"takes a batch of states\n",
    "    and a batch of actions [batch_dim, seq_len, act_dim]\n",
    "    and calculates the rewards, [batch_dim, seq_len, rewards]\"\"\"\n",
    "    def step_state_reward(state, action):\n",
    "        state = batch_step(state, action)\n",
    "        return state, (state.obs, state.reward)\n",
    "    states, x = jax.lax.scan(step_state_reward,\n",
    "                                   states,\n",
    "                                   jnp.swapaxes(actions, 0, 1))\n",
    "    obs, rewards = jax.tree_map(lambda a: jnp.swapaxes(a, 0, 1), x)\n",
    "    return obs, rewards\n",
    "\n",
    "def tokenize(actions_batch, rewards_batch):\n",
    "    @jax.vmap\n",
    "    @jax.vmap\n",
    "    def one_hot(act):\n",
    "        return jnp.zeros(shape=ACT_DIM).at[act].set(1)\n",
    "    action_tokens = one_hot(actions_batch)\n",
    "    return action_tokens, jnp.expand_dims(rewards_batch, 2)\n",
    "\n",
    "### Functions for autoregressive sampling\n",
    "\n",
    "from flax.core.frozen_dict import unfreeze, freeze\n",
    "def feed_token(model_params, cache,\n",
    "               obs, rewards, actions,\n",
    "               timesteps, ep_nums):\n",
    "    \"\"\"takes the parameters, the current model cache,\n",
    "    the token, token_type, and time_step\n",
    "    and feeds them to the model updating the cache\n",
    "    \n",
    "    Note, can process multiple tokens at once\n",
    "    token should be [batch_size, seq_len, token_dim]\n",
    "    and token_type [batch_size, seq_len]\n",
    "    time_step [batch_size, seq_len]\"\"\"\n",
    "    ra = unfreeze(model_params)\n",
    "    ra['seq']['cache'] = cache['cache']\n",
    "    return model.apply(params=ra, mutable=['cache'],\n",
    "                       states=obs,\n",
    "                       rewards=rewards,\n",
    "                       actions=actions,\n",
    "                       timesteps=timesteps,\n",
    "                       ep_nums=ep_nums)\n",
    "\n",
    "\n",
    "num_eps = 9\n",
    "ep_len = script_setting['roomsize']\n",
    "\n",
    "cache_len = (num_eps+1)*(ep_len+1)\n",
    "\n",
    "from functools import partial\n",
    "@partial(jax.jit, static_argnames=\"batch_size\")\n",
    "def init_cache(model_params, batch_size):\n",
    "    return model.apply(\n",
    "        params=model_params,\n",
    "        init_cache=True,\n",
    "        mutable=['cache'],\n",
    "        states=jnp.zeros((batch_size, cache_len, STATE_DIM)),\n",
    "        rewards=jnp.zeros((batch_size, cache_len, 1)),\n",
    "        actions=jnp.zeros((batch_size, cache_len, ACT_DIM)),\n",
    "        timesteps=jnp.zeros((batch_size, cache_len), dtype=int),\n",
    "        ep_nums=jnp.zeros((batch_size, cache_len), dtype=int))[1]\n",
    "\n",
    "def episode_roll_out(state, ep_no,\n",
    "                     cache_roll, cache_pred,\n",
    "                     params_roll, params_pred,\n",
    "                     key, sample_f, pred_f, step_num=ep_len,\n",
    "                     return_data=False):\n",
    "    init_ob, init_r = state.obs, state.reward\n",
    "    action_token = jnp.zeros((batch_size, 1, 5))\n",
    "    obs_token = jnp.expand_dims(init_ob, axis=1)\n",
    "    reward_token = init_r[..., None, None]\n",
    "    \n",
    "    @jax.vmap\n",
    "    def one_hot(act):\n",
    "        return jnp.zeros(shape=ACT_DIM).at[act].set(1)\n",
    "    @jax.vmap\n",
    "    def ind(a, i):\n",
    "        return a[i]\n",
    "    \n",
    "    def auto_step(carry, a_key):\n",
    "        (state, timestep, ep_no,\n",
    "         cache_roll, cache_pred,\n",
    "         action_token, obs_token, reward_token,\n",
    "         entropies) = carry\n",
    "        roll_ans, cache_roll = feed_token(params_roll, cache_roll,\n",
    "                                          actions=action_token,\n",
    "                                          obs=obs_token,\n",
    "                                          rewards=reward_token,\n",
    "                                          timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                              dtype=int)+timestep,\n",
    "                                          ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                            dtype=int)+ep_no)\n",
    "        pred_ans, cache_pred = feed_token(params_pred, cache_pred,\n",
    "                                          actions=action_token,\n",
    "                                          obs=obs_token,\n",
    "                                          rewards=reward_token,\n",
    "                                          timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                              dtype=int)+timestep,\n",
    "                                          ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                            dtype=int)+ep_no)\n",
    "        samp_logits = sample_f(roll_ans.last_hidden_state[:, -1, :])\n",
    "        samp_logits = jax.lax.stop_gradient(samp_logits)\n",
    "        action = jax.random.categorical(a_key, samp_logits)\n",
    "        state = env.step(state, action)\n",
    "        \n",
    "        action_token = jnp.expand_dims(one_hot(action), axis=1)\n",
    "        obs_token = jnp.expand_dims(state.obs, axis=1)\n",
    "        reward_token = state.reward[..., None, None]\n",
    "\n",
    "        pred_logits = pred_f(pred_ans.last_hidden_state[:, -1, :])\n",
    "        pred_ent = optax.softmax_cross_entropy_with_integer_labels(samp_logits\n",
    "                                                                   + pred_logits,\n",
    "                                                                   action)\n",
    "        carry = (state, timestep+1, ep_no,\n",
    "                 cache_roll, cache_pred,\n",
    "                 action_token, obs_token, reward_token,\n",
    "                 entropies + pred_ent)\n",
    "        if not return_data:\n",
    "            return carry, None\n",
    "        else:\n",
    "            return carry, (samp_logits, pred_logits, action, state)\n",
    "    \n",
    "    carry = (state, 0, ep_no,\n",
    "             cache_roll, cache_pred,\n",
    "             action_token, obs_token, reward_token,\n",
    "             jnp.zeros(batch_size))\n",
    "    carry, xs = jax.lax.scan(auto_step, carry, jax.random.split(key, step_num))\n",
    "    (state, timestep, ep_no, cache_roll, cache_pred,\n",
    "     action_token, obs_token, reward_token, entropies) = carry\n",
    "    \n",
    "    roll_ans, cache_roll = feed_token(params_roll, cache_roll,\n",
    "                                      actions=action_token,\n",
    "                                      obs=obs_token,\n",
    "                                      rewards=reward_token,\n",
    "                                      timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                          dtype=int)+timestep,\n",
    "                                      ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                        dtype=int)+ep_no)\n",
    "    pred_ans, cache_pred = feed_token(params_pred, cache_pred,\n",
    "                                      actions=action_token,\n",
    "                                      obs=obs_token,\n",
    "                                      rewards=reward_token,\n",
    "                                      timesteps=jnp.zeros((batch_size, 1),\n",
    "                                                          dtype=int)+timestep,\n",
    "                                      ep_nums=jnp.zeros((batch_size, 1),\n",
    "                                                        dtype=int)+ep_no)\n",
    "    if not return_data:\n",
    "        return state, ep_no+1, cache_roll, cache_pred, entropies\n",
    "    else:\n",
    "        return state, ep_no+1, cache_roll, cache_pred, entropies, xs\n",
    "\n",
    "\n",
    "def exploit(state, ep_no,\n",
    "            cache_roll, cache_pred,\n",
    "            params_roll, params_pred, \n",
    "            key, samp_t = 1, step_num=ep_len,\n",
    "            return_data=False, rand_roll=False):\n",
    "    \"\"\"autoregressively exploits\n",
    "    \n",
    "    sample_f = exploit with epsilon and temperature\n",
    "    pred_fs = (exploit (no epsilon, no temperature), non-exploit)\n",
    "    \n",
    "    return updated state, cache, episode return, accumulated cross entropy sums\n",
    "    \"\"\"\n",
    "    ## sample_f updated based on epsilon and t, as done before\n",
    "    ## pred_fs as before, then the following\n",
    "    def sample_exploit(hidden_state):\n",
    "        return jax.lax.stop_gradient(model.pred_exp.apply(params_roll['pred_max'],\n",
    "                                                          hidden_state) * samp_t)\n",
    "    def pred_max(hidden_state):\n",
    "        return model.pred_exp.apply(params_pred['pred_max'],\n",
    "                                      hidden_state)\n",
    "    return episode_roll_out(state=state, ep_no=ep_no,\n",
    "                            params_roll=params_roll,\n",
    "                            params_pred=params_pred,\n",
    "                            cache_roll=cache_roll,\n",
    "                            cache_pred=cache_pred,\n",
    "                            key=key,\n",
    "                            sample_f=sample_exploit,\n",
    "                            pred_f=pred_max,\n",
    "                            return_data=return_data,\n",
    "                            step_num=step_num)\n",
    "\n",
    "\n",
    "def explore(state, ep_no,\n",
    "            cache_roll, cache_pred,\n",
    "            params_roll, params_pred, \n",
    "            key, samp_t = 1, step_num=ep_len,\n",
    "            return_data=False, rand_roll=False):\n",
    "    \"\"\"autoregressively exploits\n",
    "    \n",
    "    sample_f = exploit with epsilon and temperature\n",
    "    pred_fs = (exploit (no epsilon, no temperature), non-exploit)\n",
    "    \n",
    "    return updated state, cache, episode return, accumulated cross entropy sums\n",
    "    \"\"\"\n",
    "    def sample_exploit(hidden_state):\n",
    "        return jax.lax.stop_gradient(model.pred_exp.apply(params_roll['pred_exp'],\n",
    "                                                          hidden_state) * samp_t)\n",
    "    def pred_max(hidden_state):\n",
    "        return model.pred_exp.apply(params_pred['pred_exp'],\n",
    "                                      hidden_state)\n",
    "    return episode_roll_out(state=state, ep_no=ep_no,\n",
    "                            cache_roll=cache_roll,\n",
    "                            cache_pred=cache_pred,\n",
    "                            params_roll=params_roll,\n",
    "                            params_pred=params_pred,\n",
    "                            key=key,\n",
    "                            sample_f=sample_exploit,\n",
    "                            pred_f=pred_max,\n",
    "                            return_data=return_data,\n",
    "                            step_num=step_num)\n",
    "\n",
    "\n",
    "def train_exploit_explore(params_pred, params_roll,\n",
    "                          key, step_num=ep_len, ep_num=num_eps,\n",
    "                          samp_t=1, return_data=False,\n",
    "                          weighted=False):\n",
    "    \"\"\"does iterated rollouts\"\"\"\n",
    "    skey, rkey = jax.random.split(key, 2)\n",
    "    state = env.meta_reset(skey)\n",
    "    cache_roll = init_cache(params_roll, batch_size)\n",
    "    cache_pred = init_cache(params_pred, batch_size)\n",
    "\n",
    "    def epstep(carry, key):\n",
    "        (cache_roll, cache_pred, n, max_in_context,\n",
    "         max_ent, exp_ent) = carry \n",
    "\n",
    "        e_key, m_key = jax.random.split(key, 2)\n",
    "        \n",
    "        exp_ans = explore(state, n,\n",
    "                          cache_roll=cache_roll,\n",
    "                          cache_pred=cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=e_key,\n",
    "                          samp_t=samp_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies, exp_xs) = exp_ans\n",
    "        else:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies) = exp_ans\n",
    "        \n",
    "        max_ans = exploit(state, e_n,\n",
    "                          cache_roll=exp_cache_roll,\n",
    "                          cache_pred=exp_cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=m_key,\n",
    "                          samp_t=samp_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (max_state, m_n, max_cache_roll, max_cache_pred, \n",
    "             m_entropies, max_xs) = max_ans\n",
    "        else:\n",
    "            (max_state, m_n, max_cache_roll, max_cache_pred, \n",
    "             m_entropies) = max_ans\n",
    "            \n",
    "\n",
    "        mul = max_state.reward >= max_in_context\n",
    "        if weighted:\n",
    "            mul = mul*(1+max_state.reward-max_in_context)\n",
    "        max_in_context = jnp.maximum(jnp.maximum(exp_state.reward, max_state.reward), max_in_context)\n",
    "        \n",
    "        max_ent = (m_entropies*mul).mean() + max_ent\n",
    "        exp_ent = (e_entropies*mul).mean() + exp_ent\n",
    "        \n",
    "        carry = (exp_cache_roll, exp_cache_pred, e_n, max_in_context,\n",
    "                 max_ent, exp_ent)\n",
    "        \n",
    "        if return_data:\n",
    "            return carry, (exp_xs, max_xs, max_state.reward)\n",
    "        return carry, (max_state.reward, exp_state.reward)\n",
    "    \n",
    "    carry = (cache_roll, cache_pred, 0,\n",
    "             jnp.zeros(shape=(batch_size,)),\n",
    "             jnp.zeros(()), jnp.zeros(()))\n",
    "    carry, max_vals = jax.lax.scan(epstep, carry, jax.random.split(rkey, ep_num))\n",
    "    \n",
    "    if return_data:\n",
    "        return carry, max_vals\n",
    "    else:\n",
    "        max_ent, exp_ent = carry[-2:]\n",
    "        max_reward, exp_reward = max_vals\n",
    "        return ((max_ent+exp_ent)/ep_num,\n",
    "                (max_ent, exp_ent,\n",
    "                 max_reward.mean(axis=1), exp_reward.mean(axis=1)))\n",
    "    \n",
    "    \n",
    "@jax.jit\n",
    "def train_step(carry, _):\n",
    "    params_roll, params_pred, opt_state, key, samp_t = carry\n",
    "    next_key, data_key, drop_key = jax.random.split(key, 3)\n",
    "    loss, grad = jax.value_and_grad(train_exploit_explore,\n",
    "                                    has_aux=True)(params_pred, params_roll=params_roll, key=data_key, samp_t=samp_t,\n",
    "                                                  weighted=script_setting['weighting'])\n",
    "    updates, opt_state = optimizer.update(grad, opt_state, params_pred)\n",
    "    params_pred = optax.apply_updates(params_pred, updates)\n",
    "    return (params_roll, params_pred, opt_state, next_key, samp_t), loss\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(carry, _):\n",
    "    params_roll, params_pred, opt_state, key, samp_t = carry\n",
    "    next_key, data_key, drop_key = jax.random.split(key, 3)\n",
    "    loss, grad = jax.value_and_grad(train_exploit_explore,\n",
    "                                    has_aux=True)(params_pred, params_roll=params_pred, key=data_key, samp_t=10)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state, params_pred)\n",
    "    params_pred = optax.apply_updates(params_pred, updates)\n",
    "    return (params_roll, params_pred, opt_state, next_key, samp_t), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "after-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_exploit_then_explore(params_pred, params_roll, state,\n",
    "                          key, step_num=ep_len, ep_num=num_eps, k=1,\n",
    "                          e_t=1, m_t=1, return_data=False):\n",
    "    \"\"\"does iterated rollouts, explores then exploit\"\"\"\n",
    "    skey, rkey = jax.random.split(key, 2)\n",
    "    cache_roll = init_cache(params_roll, batch_size)\n",
    "    cache_pred = init_cache(params_pred, batch_size)\n",
    "\n",
    "\n",
    "    def epstep_explore(carry, key):\n",
    "        (cache_roll, cache_pred, n) = carry \n",
    "\n",
    "        e_key, _ = jax.random.split(key, 2)\n",
    "        exp_ans = explore(state, n,\n",
    "                          cache_roll=cache_roll,\n",
    "                          cache_pred=cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=e_key,\n",
    "                          samp_t=e_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies, exp_xs) = exp_ans\n",
    "        else:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies) = exp_ans\n",
    "\n",
    "        carry = (exp_cache_roll, exp_cache_pred, e_n)\n",
    "        \n",
    "        if return_data:\n",
    "            return carry, (exp_xs, exp_state.reward)\n",
    "        return carry, (exp_state.reward)\n",
    "    \n",
    "    def epstep_exploit(carry, key):\n",
    "        (cache_roll, cache_pred, n) = carry \n",
    "\n",
    "        e_key, _ = jax.random.split(key, 2)\n",
    "        exp_ans = exploit(state, n,\n",
    "                          cache_roll=cache_roll,\n",
    "                          cache_pred=cache_pred,\n",
    "                          params_roll=params_roll,\n",
    "                          params_pred=params_pred,\n",
    "                          key=e_key,\n",
    "                          samp_t=e_t,\n",
    "                          return_data=return_data,\n",
    "                          step_num=step_num)\n",
    "        if return_data:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies, exp_xs) = exp_ans\n",
    "        else:\n",
    "            (exp_state, e_n, exp_cache_roll, exp_cache_pred, \n",
    "             e_entropies) = exp_ans\n",
    "\n",
    "        carry = (exp_cache_roll, exp_cache_pred, e_n)\n",
    "        \n",
    "        if return_data:\n",
    "            return carry, (exp_xs, exp_state.reward)\n",
    "        return carry, (exp_state.reward)\n",
    "    \n",
    "    \n",
    "    \n",
    "    carry = (cache_roll, cache_pred, 0)\n",
    "    \n",
    "    carry, exp_vals = jax.lax.scan(epstep_explore, carry, jax.random.split(rkey, k))\n",
    "    \n",
    "    carry, max_vals = jax.lax.scan(epstep_exploit, carry, jax.random.split(rkey, ep_num-k))\n",
    "    \n",
    "    if return_data:\n",
    "        return carry, exp_vals, max_vals\n",
    "    else:\n",
    "        return exp_vals, max_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-ending",
   "metadata": {},
   "source": [
    "### Load $\\rho=-4$ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# load the minval = -4 model, (associated with -4 environment defined above)\n",
    "with open(f\"roomsize_9batchsize_128weighting_Trueseed_{42}k_8t_1minval_-4/run_data.pkl\",\n",
    "          \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "    first_explore_runs = data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-criminal",
   "metadata": {},
   "source": [
    "### Example of evaluating $k=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imported-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=10000000\n",
    "vis_state = env.meta_reset(jax.random.PRNGKey(0))\n",
    "ans = visualize_exploit_then_explore(first_explore_runs, first_explore_runs, \n",
    "                               vis_state, jax.random.PRNGKey(42), e_t=T, m_t=T,\n",
    "                               k=2, return_data=True, ep_num=10)\n",
    "explore_vals, exploit_vals = ans[1], ans[2]\n",
    "import numpy as np\n",
    "# n.b. the environment state.reward field records cumulative reward!\n",
    "explore_rewards = np.diff(np.pad(explore_vals[0][-1].reward.mean(axis=-1),\n",
    "                                 ((0,0), (1, 0))), axis=-1).reshape(-1)\n",
    "exploit_rewards = np.diff(np.pad(exploit_vals[0][-1].reward.mean(axis=-1),\n",
    "                                 ((0,0), (1, 0))), axis=-1).reshape(-1)\n",
    "total_rewards = np.cumsum(np.concatenate((explore_rewards, exploit_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominant-geneva",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd8d81b5e20>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
